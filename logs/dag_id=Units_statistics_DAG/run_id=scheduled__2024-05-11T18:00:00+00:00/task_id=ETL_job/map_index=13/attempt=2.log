[2024-05-11T18:21:50.200+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Units_statistics_DAG.ETL_job scheduled__2024-05-11T18:00:00+00:00 map_index=13 [queued]>
[2024-05-11T18:21:50.213+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Units_statistics_DAG.ETL_job scheduled__2024-05-11T18:00:00+00:00 map_index=13 [queued]>
[2024-05-11T18:21:50.214+0000] {taskinstance.py:2193} INFO - Starting attempt 2 of 4
[2024-05-11T18:21:50.232+0000] {taskinstance.py:2217} INFO - Executing <Mapped(_PythonDecoratedOperator): ETL_job> on 2024-05-11 18:00:00+00:00
[2024-05-11T18:21:50.240+0000] {standard_task_runner.py:60} INFO - Started process 946842 to run task
[2024-05-11T18:21:50.250+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'Units_statistics_DAG', 'ETL_job', 'scheduled__2024-05-11T18:00:00+00:00', '--job-id', '51310', '--raw', '--subdir', 'DAGS_FOLDER/Units_dag.py', '--cfg-path', '/tmp/tmp2cxoqko3', '--map-index', '13']
[2024-05-11T18:21:50.252+0000] {standard_task_runner.py:88} INFO - Job 51310: Subtask ETL_job
[2024-05-11T18:21:50.337+0000] {task_command.py:423} INFO - Running <TaskInstance: Units_statistics_DAG.ETL_job scheduled__2024-05-11T18:00:00+00:00 map_index=13 [running]> on host a09da322e808
[2024-05-11T18:21:50.484+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='abeer-araby' AIRFLOW_CTX_DAG_ID='Units_statistics_DAG' AIRFLOW_CTX_TASK_ID='ETL_job' AIRFLOW_CTX_EXECUTION_DATE='2024-05-11T18:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-11T18:00:00+00:00'
[2024-05-11T18:21:50.485+0000] {Units_dag.py:98} INFO - i: 130000, chunk: 10000
[2024-05-11T18:21:50.485+0000] {Units_dag.py:99} INFO - child token is::: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczovL2FwaS5hZmFxeS5zYS9hdXRoL2xvZ2luX2FzIiwiaWF0IjoxNzE1NDUxNjA0LCJleHAiOjE3MTgwNDM2MDQsIm5iZiI6MTcxNTQ1MTYwNCwianRpIjoiREEwM2pNT296ZEJPR0ljYSIsInN1YiI6IjVkNjNlNTFlMDNlZDUyOTJhNDJjMjRlNiIsInBydiI6IjI3MGVjZmM3ZWEzZWQ5MzdlYTg0OTM2MmEzYTUwOTEwYzZkOGNlNGYiLCJsb2dpbl9hc19pZCI6IjY1N2YwYWQ3M2Y5NzcyOTVjZjA1NTc2YSJ9.TjS5md_Kx3ttLSICoVHR528xjVuF35HDYfzYZi0utrk
[2024-05-11T18:22:07.636+0000] {Units_dag.py:103} INFO - {'_id': '651175004693e901d2c4648a', 'imei': '356173061718560', 'updated_at': '2024-04-18 11:18:59', 'custom_fields': [], 'creator': '', 'company': '', 'owner': '', 'last_update': {'dtt': 1695700198970, 'dts': 1695700206901, 'spd': 0, 'ang': 0, 'alt': 46, 'chPrams': {'rssi': {'v': 3, 'cdt': 1694032987060}, 'protocol': {'v': 'teltonika', 'cdt': 1693193085860}, 'output1': {'v': False, 'cdt': 1693460607690}, 'output2': {'v': False, 'cdt': 1694032987060}, 'ePwrV': {'v': 25.211000000000002, 'cdt': 1694473565200}, 'sat': {'v': 17, 'cdt': 1695700198970}, 'event': {'v': 0, 'cdt': 1693658155950}, 'di2': {'v': 0, 'cdt': 1692976140120}, 'priority': {'v': 0, 'cdt': 1693193085860}, 'di1': {'v': 0, 'cdt': 1694032987060}, 'temp1': {'v': 300, 'cdt': 1693460607690}}, 'prms': {'protocol': 'teltonika', 'priority': 0, 'sat': 17, 'event': 0}, 'devPrms': ['protocol', 'priority', 'sat', 'event'], 'old_params': {'protocol': 'teltonika', 'priority': 0, 'sat': 16, 'event': 0}, 'vLoc': 1, 'vCon': 1, 'ip': '51.39.22.246', 'rl': 0, 'trl': 92085.1635, 'mdu': 0, 'tmdu': 5305327, 'eidl': 0, 'teidl': 2346072, 'fc': 0, 'tfc': 0, 'acc': 0, 'accOn': 39057998, 'accOff': 38587646, 'sdu': 240, 'tsdu': 1228213, 'lat': 26.381024, 'lng': 50.0887648}, 'counters': {'engine_hours': 39057998, 'last_acc': 0, 'odometer': 92085.1635}, 'is_wasl_connected': 'Not Connected', 'iconUrl': '', 'hasCCTV': False}
[2024-05-11T18:22:08.192+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://dbelk2.afaqy.local:9200' using TLS with verify_certs=False is insecure
  _transport = transport_class(

[2024-05-11T18:22:08.234+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://dbelk3.afaqy.local:9200' using TLS with verify_certs=False is insecure
  _transport = transport_class(

[2024-05-11T18:22:08.277+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://dbelk1.afaqy.local:9200' using TLS with verify_certs=False is insecure
  _transport = transport_class(

[2024-05-11T18:22:08.302+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dbelk2.afaqy.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(

[2024-05-11T18:22:08.395+0000] {_transport.py:335} INFO - GET https://dbelk2.afaqy.local:9200/_cluster/health [status:200 duration:0.116s]
[2024-05-11T18:22:08.786+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dbelk3.afaqy.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(

[2024-05-11T18:22:08.908+0000] {_transport.py:335} INFO - PUT https://dbelk3.afaqy.local:9200/units_statistics_***/_bulk [status:200 duration:0.141s]
[2024-05-11T18:22:09.244+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/Units_dag.py", line 111, in ETL_job
    Elk_client.elk_pushData(Globals.index_name,units_list_update)
  File "/opt/airflow/dags/units_statistics/elk_manager.py", line 69, in elk_pushData
    helpers.bulk(self.elk_client, docs_list, index=index_name, chunk_size=batch)
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 355, in _process_bulk_chunk
    yield from gen
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 274, in _process_bulk_chunk_success
    raise BulkIndexError(f"{len(errors)} document(s) failed to index.", errors)
elasticsearch.helpers.BulkIndexError: 10000 document(s) failed to index.
[2024-05-11T18:22:09.263+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=Units_statistics_DAG, task_id=ETL_job, map_index=13, execution_date=20240511T180000, start_date=20240511T182150, end_date=20240511T182209
[2024-05-11T18:22:09.281+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 51310 for task ETL_job (10000 document(s) failed to index.; 946842)
[2024-05-11T18:22:09.361+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-05-11T18:22:09.394+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
