[2024-05-11T15:21:48.245+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Units_statistics_DAG.ETL_job scheduled__2024-05-11T15:00:00+00:00 map_index=13 [queued]>
[2024-05-11T15:21:48.260+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Units_statistics_DAG.ETL_job scheduled__2024-05-11T15:00:00+00:00 map_index=13 [queued]>
[2024-05-11T15:21:48.261+0000] {taskinstance.py:2193} INFO - Starting attempt 2 of 4
[2024-05-11T15:21:48.281+0000] {taskinstance.py:2217} INFO - Executing <Mapped(_PythonDecoratedOperator): ETL_job> on 2024-05-11 15:00:00+00:00
[2024-05-11T15:21:48.288+0000] {standard_task_runner.py:60} INFO - Started process 943488 to run task
[2024-05-11T15:21:48.301+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'Units_statistics_DAG', 'ETL_job', 'scheduled__2024-05-11T15:00:00+00:00', '--job-id', '50919', '--raw', '--subdir', 'DAGS_FOLDER/Units_dag.py', '--cfg-path', '/tmp/tmp8nhh6yi_', '--map-index', '13']
[2024-05-11T15:21:48.303+0000] {standard_task_runner.py:88} INFO - Job 50919: Subtask ETL_job
[2024-05-11T15:21:48.401+0000] {task_command.py:423} INFO - Running <TaskInstance: Units_statistics_DAG.ETL_job scheduled__2024-05-11T15:00:00+00:00 map_index=13 [running]> on host a09da322e808
[2024-05-11T15:21:48.579+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='abeer-araby' AIRFLOW_CTX_DAG_ID='Units_statistics_DAG' AIRFLOW_CTX_TASK_ID='ETL_job' AIRFLOW_CTX_EXECUTION_DATE='2024-05-11T15:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-05-11T15:00:00+00:00'
[2024-05-11T15:21:48.581+0000] {Units_dag.py:98} INFO - i: 130000, chunk: 10000
[2024-05-11T15:21:48.582+0000] {Units_dag.py:99} INFO - child token is::: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJodHRwczovL2FwaS5hZmFxeS5zYS9hdXRoL2xvZ2luX2FzIiwiaWF0IjoxNzE1NDQwODAzLCJleHAiOjE3MTgwMzI4MDMsIm5iZiI6MTcxNTQ0MDgwMywianRpIjoiaGtzNUR1WjZXcTdEdVdoSiIsInN1YiI6IjVkNjNlNTFlMDNlZDUyOTJhNDJjMjRlNiIsInBydiI6IjI3MGVjZmM3ZWEzZWQ5MzdlYTg0OTM2MmEzYTUwOTEwYzZkOGNlNGYiLCJsb2dpbl9hc19pZCI6IjY1N2YwYWQ3M2Y5NzcyOTVjZjA1NTc2YSJ9.hmpQUOqYZeEbF40CmY0kGoRTkfII7uLyEHlDiKHeoWg
[2024-05-11T15:22:08.708+0000] {Units_dag.py:103} INFO - {'_id': '651175004693e901d2c4648a', 'imei': '356173061718560', 'updated_at': '2024-04-18 11:18:59', 'custom_fields': [], 'creator': '', 'company': '', 'owner': '', 'last_update': {'dtt': 1695700198970, 'dts': 1695700206901, 'spd': 0, 'ang': 0, 'alt': 46, 'chPrams': {'rssi': {'v': 3, 'cdt': 1694032987060}, 'protocol': {'v': 'teltonika', 'cdt': 1693193085860}, 'output1': {'v': False, 'cdt': 1693460607690}, 'output2': {'v': False, 'cdt': 1694032987060}, 'ePwrV': {'v': 25.211000000000002, 'cdt': 1694473565200}, 'sat': {'v': 17, 'cdt': 1695700198970}, 'event': {'v': 0, 'cdt': 1693658155950}, 'di2': {'v': 0, 'cdt': 1692976140120}, 'priority': {'v': 0, 'cdt': 1693193085860}, 'di1': {'v': 0, 'cdt': 1694032987060}, 'temp1': {'v': 300, 'cdt': 1693460607690}}, 'prms': {'protocol': 'teltonika', 'priority': 0, 'sat': 17, 'event': 0}, 'devPrms': ['protocol', 'priority', 'sat', 'event'], 'old_params': {'protocol': 'teltonika', 'priority': 0, 'sat': 16, 'event': 0}, 'vLoc': 1, 'vCon': 1, 'ip': '51.39.22.246', 'rl': 0, 'trl': 92085.1635, 'mdu': 0, 'tmdu': 5305327, 'eidl': 0, 'teidl': 2346072, 'fc': 0, 'tfc': 0, 'acc': 0, 'accOn': 39057998, 'accOff': 38587646, 'sdu': 240, 'tsdu': 1228213, 'lat': 26.381024, 'lng': 50.0887648}, 'counters': {'engine_hours': 39057998, 'last_acc': 0, 'odometer': 92085.1635}, 'is_wasl_connected': 'Not Connected', 'iconUrl': '', 'hasCCTV': False}
[2024-05-11T15:22:09.678+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://dbelk1.afaqy.local:9200' using TLS with verify_certs=False is insecure
  _transport = transport_class(

[2024-05-11T15:22:09.745+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://dbelk2.afaqy.local:9200' using TLS with verify_certs=False is insecure
  _transport = transport_class(

[2024-05-11T15:22:09.812+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://dbelk3.afaqy.local:9200' using TLS with verify_certs=False is insecure
  _transport = transport_class(

[2024-05-11T15:22:09.844+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dbelk1.afaqy.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(

[2024-05-11T15:22:09.904+0000] {_transport.py:335} INFO - GET https://dbelk1.afaqy.local:9200/_cluster/health [status:200 duration:0.084s]
[2024-05-11T15:22:12.065+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dbelk2.afaqy.local'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings
  warnings.warn(

[2024-05-11T15:22:13.084+0000] {_transport.py:335} INFO - PUT https://dbelk2.afaqy.local:9200/units_statistics_***/_bulk [status:200 duration:2.788s]
[2024-05-11T15:22:13.354+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/Units_dag.py", line 111, in ETL_job
    Elk_client.elk_pushData(Globals.index_name,units_list_update)
  File "/opt/airflow/dags/units_statistics/elk_manager.py", line 69, in elk_pushData
    helpers.bulk(self.elk_client, docs_list, index=index_name, chunk_size=batch)
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 521, in bulk
    for ok, item in streaming_bulk(
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 436, in streaming_bulk
    for data, (ok, info) in zip(
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 355, in _process_bulk_chunk
    yield from gen
  File "/home/airflow/.local/lib/python3.8/site-packages/elasticsearch/helpers/actions.py", line 274, in _process_bulk_chunk_success
    raise BulkIndexError(f"{len(errors)} document(s) failed to index.", errors)
elasticsearch.helpers.BulkIndexError: 1628 document(s) failed to index.
[2024-05-11T15:22:13.365+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=Units_statistics_DAG, task_id=ETL_job, map_index=13, execution_date=20240511T150000, start_date=20240511T152148, end_date=20240511T152213
[2024-05-11T15:22:13.383+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 50919 for task ETL_job (1628 document(s) failed to index.; 943488)
[2024-05-11T15:22:13.440+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-05-11T15:22:13.475+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
